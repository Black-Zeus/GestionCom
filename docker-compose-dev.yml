services:

  # =========================
  # NGINX - Reverse Proxy
  # =========================
  nginx:
    container_name: ${PROJECT_NAME}-nginx
    build:
      context: .
      dockerfile: docker/dev/dockerfile.nginx.dev
    image: ${PROJECT_NAME}/nginx:dev.v0.1
    labels:
      - stack=inventario
    depends_on:
      - frontend
    volumes:
      - ./logs/nginx:/var/log/nginx # Opcional: logging del reverse proxy
    environment:
      - PROJECT_NAME=${PROJECT_NAME}
      - FRONTEND_PORT_INTERNAL=${FRONTEND_PORT_INTERNAL}
      - BACKEND_API_PORT_INTERNAL=${BACKEND_API_PORT_INTERNAL}
      - DOCS_API_PORT_INTERNAL=${DOCS_API_PORT_INTERNAL}
      - TASKS_API_PORT_INTERNAL=${TASKS_API_PORT_INTERNAL}
    ports:
      - "${NGINX_PORT}:${NGINX_PORT_INTERNAL}"
    networks:
      - ${EXTERNAL_NETWORK}
      - ${INTERNAL_NETWORK}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "128M"
        reservations:
          cpus: "0.25"
          memory: "64M"

  # =========================
  # FRONTEND - React/NodeJS
  # =========================
  frontend:
    container_name: ${PROJECT_NAME}-frontend
    build:
      context: .
      dockerfile: docker/dev/dockerfile.frontend.dev
    image: ${PROJECT_NAME}/frontend:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/frontend:/app
      - /app/node_modules
      - ./logs/frontend:/var/log/app
    ports:
      - "${FRONTEND_PORT}:${FRONTEND_PORT_INTERNAL}"
    command: [ "npm", "run", "dev" ]
    depends_on:
      - backend-api
      - backend-docs
      - backend-tasks
      - backend-worker
    environment:
      - ENV=${ENV}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - ${INTERNAL_NETWORK}
    env_file:
      - ./volumes/frontend/.env
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "256M"
        reservations:
          cpus: "0.5"
          memory: "128M"

  # =========================
  # BACKEND API - Api COnsultas a Base de Datos
  # =========================
  backend-api:
    container_name: ${PROJECT_NAME}-backend-api
    build:
      context: .
      dockerfile: docker/dev/dockerfile.backend-api
    image: ${PROJECT_NAME}/backend-api:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/backend-api:/app
      - ./logs/backend-api:/var/log/app
    depends_on:
      mariadb:
        condition: service_healthy
    ports:
      - "${BACKEND_API_PORT}:${BACKEND_API_PORT_INTERNAL}"
    command: uvicorn main:app --host ${BACKEND_API_HOST} --port ${BACKEND_API_PORT_INTERNAL} --reload
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - ${INTERNAL_NETWORK}
    env_file:
      - ./volumes/backend-api/.env
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "256M"
        reservations:
          cpus: "0.5"
          memory: "128M"

  # =========================
  # BACKEND DOCS - Generaci√≥n de Documentos / Conexion Minio
  # =========================
  backend-docs:
    container_name: ${PROJECT_NAME}-backend-docs
    build:
      context: .
      dockerfile: docker/dev/dockerfile.backend-docs
    image: ${PROJECT_NAME}/backend-docs:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/backend-docs:/app
      - ./logs/backend-docs:/var/log/app
    networks:
      - ${INTERNAL_NETWORK}
    depends_on:
      minio:
        condition: service_healthy
    ports:
      - ${DOCS_API_PORT_INTERNAL}
    command: uvicorn main:app --host ${DOCS_API_HOST} --port ${DOCS_API_PORT_INTERNAL}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    env_file:
      - ./volumes/backend-docs/.env
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "256M"
        reservations:
          cpus: "0.25"
          memory: "128M"

  # =========================
  # BACKEND TASKS - Ejecuci√≥n de Tareas en segundo plano
  # =========================
  backend-tasks:
    container_name: ${PROJECT_NAME}-backend-tasks
    build:
      context: .
      dockerfile: docker/dev/dockerfile.backend-tasks
    image: ${PROJECT_NAME}/backend-tasks:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/backend-tasks:/app
      - ./logs/backend-tasks:/var/log/app
    networks:
      - ${INTERNAL_NETWORK}
    depends_on:
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    ports:
      - "${TASKS_API_PORT}:${TASKS_API_PORT_INTERNAL}"
    command: uvicorn main:app --host ${TASKS_API_HOST} --port ${TASKS_API_PORT_INTERNAL}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    env_file:
      - ./volumes/backend-tasks/.env
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "256M"
        reservations:
          cpus: "0.25"
          memory: "128M"

  # =========================
  # BACKEND WORKER - Procesador de Colas
  # =========================
  backend-worker:
    container_name: ${PROJECT_NAME}-backend-worker
    build:
      context: .
      dockerfile: docker/dev/dockerfile.backend-worker
    image: ${PROJECT_NAME}/backend-worker:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/backend-worker:/app
      - ./logs/backend-worker:/var/log/app
    networks:
      - ${INTERNAL_NETWORK}
    depends_on:      
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    command: [ "celery", "-A", "tasks", "worker", "--loglevel=${WORKER_LOG_LEVEL}", "--queues=${WORKER_QUEUES}" ]
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    env_file:
      - ./volumes/backend-worker/.env
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "512M"
        reservations:
          cpus: "0.5"
          memory: "256M"

  # =========================
  # WORKER NOTIFICATIONS - Procesador de Notificaciones en Tiempo Real
  # =========================
  worker-notifications:
    container_name: ${PROJECT_NAME}-worker-notifications
    build:
      context: .
      dockerfile: docker/dev/dockerfile.backend-worker
    image: ${PROJECT_NAME}/worker-notifications:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/backend-worker:/app
      - ./logs/backend-notification:/var/log/app
    networks:
      - ${INTERNAL_NETWORK}
    depends_on:
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    command: [ "celery", "-A", "notifications", "worker", "--loglevel=${WORKER_LOG_LEVEL}", "--queues=notifications" ]
    # üèóÔ∏è Comando de ejecuci√≥n:
    # - Celery Worker especializado en notificaciones en tiempo real.
    # - Solo procesa tareas en la cola "notifications".
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    env_file:
      - ./volumes/backend-worker/.env
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "256M"
        reservations:
          cpus: "0.25"
          memory: "128M"

  # =========================
  # BACKEND BEAT - Planificador de Tareas Autom√°ticas
  # =========================
  backend-beat:
    container_name: ${PROJECT_NAME}-backend-beat
    build:
      context: .
      dockerfile: docker/dev/dockerfile.backend-worker
    image: ${PROJECT_NAME}/backend-beat:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/backend-worker:/app
      - ./logs/backend-beats:/var/log/app
    networks:
      - ${INTERNAL_NETWORK}
    depends_on:
      - backend-worker
    command: [ "celery", "-A", "beat", "beat", "--loglevel=${WORKER_LOG_LEVEL}" ]
    # üèóÔ∏è Comando de ejecuci√≥n:
    # - Celery Beat programa tareas recurrentes sin necesidad de cronjobs.
    # - Se usa para ejecutar procesos autom√°ticos como descarga de datos de SIBIF.
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    env_file:
      - ./volumes/backend-worker/.env
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "256M"
        reservations:
          cpus: "0.25"
          memory: "128M"

  # =========================
  # MINIO - S3 Object Storage
  # =========================
  minio:
    container_name: ${PROJECT_NAME}-minio
    build:
      context: .
      dockerfile: docker/dockerfile.minio
    image: ${PROJECT_NAME}/minio:dev.v0.1
    labels:
      - stack=inventario
    volumes:
      - ./volumes/minio:/data
      - ./logs/minio:/var/log/minio
    expose:
      - "${MINIO_PORT}:${MINIO_PORT}"
    ports:
      - "${MINIO_CONSOLE_PORT}:${MINIO_CONSOLE_PORT}"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://${MINIO_HOST}:${MINIO_PORT}/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - ${INTERNAL_NETWORK}
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "512M"
        reservations:
          cpus: "0.5"
          memory: "256M"

  # =========================
  # MAILPIT - Mail Testing
  # =========================
  mailpit:
    container_name: ${PROJECT_NAME}-mailpit
    image: axllent/mailpit:v1.21.6
    expose:
      - "${MAILPIT_SMTP_PORT}:${MAILPIT_SMTP_PORT}"
    ports:
      - "${MAILPIT_UI_PORT}:${MAILPIT_UI_PORT}"
    labels:
      - stack=inventario
    volumes:
      - ./volumes/mailpit:/data
      - ./logs/mailpit:/var/log/mailpit
    environment:
      MP_STORAGE: ${MAILPIT_STORAGE}
      MP_UI_COLOR: ${MAILPIT_UI_COLOR}
      MP_LOGGING: "true"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - ${INTERNAL_NETWORK}
    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: "128M"
        reservations:
          cpus: "0.1"
          memory: "64M"

  # =========================
  # MARIADB - Base de Datos
  # =========================
  mariadb:
    container_name: ${PROJECT_NAME}-mariadb
    build:
      context: .
      dockerfile: docker/dockerfile.mysql
    image: ${PROJECT_NAME}/mariadb:10.6
    ports:
      - "${MYSQL_PORT}:${MYSQL_PORT}"
    labels:
      - stack=inventario
    volumes:
      - ./volumes/mariadb/db:/var/lib/mysql      
      - ./logs/mariadb:/var/log/mysql
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - ${INTERNAL_NETWORK}
    healthcheck:
      test: [ "CMD", "mysqladmin", "ping", "-h", "localhost" , "-u", "${MYSQL_USER}","-p${MYSQL_PASSWORD}" ]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "1G"
        reservations:
          cpus: "0.5"
          memory: "512M"

  # =========================
  # RABBITMQ - Mensajer√≠a
  # =========================
  rabbitmq:
    image: rabbitmq:4.0.5-management-alpine
    container_name: ${PROJECT_NAME}-rabbitmq
    expose:
      - "${RABBITMQ_PORT}"  # Habilita la comunicaci√≥n interna entre contenedores
    ports:      
      - "${RABBITMQ_UI_PORT}:${RABBITMQ_UI_PORT}"  # Publica la interfaz de administraci√≥n en el host
    labels:
      - stack=inventario
    volumes:
      - ./volumes/rabbitmq:/var/lib/rabbitmq
      - ./logs/rabbitmq:/var/log/rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - ${INTERNAL_NETWORK}
    healthcheck:
      test: [ "CMD", "rabbitmqctl", "status" ]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "256M"
        reservations:
          cpus: "0.25"
          memory: "128M"

  # =========================
  # REDIS - Cache
  # =========================
  redis:
    build:
      context: .
      dockerfile: docker/dockerfile.redis
    image: ${PROJECT_NAME}/redis:7.2
    container_name: ${PROJECT_NAME}-redis
    expose:
      - "${REDIS_PORT}"
    labels:
      - stack=inventario
    volumes:
      - ./volumes/redis/data:/data
      - ./logs/redis:/var/log/redis
      - ./scripts/redis/redis.conf:/etc/redis/redis.conf
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - ${INTERNAL_NETWORK}
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "256M"
        reservations:
          cpus: "0.25"
          memory: "128M"

  # =========================
  # REDISINSIGHT - Panel Web para Redis
  # =========================
  redisinsight:
    image: redis/redisinsight:2.66
    container_name: ${PROJECT_NAME}-redisinsight
    ports:
      - "${REDIS_PORT_PANEL}:5540"
    labels:
      - stack=inventario
    volumes:
      - ./volumes/redisinsight/db:/db
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - ${INTERNAL_NETWORK}
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDISINSIGHT_REDIS_URI: "redis://default:${REDIS_PASSWORD}@${PROJECT_NAME}-redis:${REDIS_PORT}/0"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "256M"
        reservations:
          cpus: "0.25"
          memory: "128M"

# =========================
# NETWORKS - Redes Docker
# =========================
networks:
  internal:
    driver: bridge
  external:
    driver: bridge
    ipam:
      config:
        - subnet: ${EXTERNAL_SUBNET}
